{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bcf0e7-eb0d-40f3-8c93-75bf8e743a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78a42b7-52ac-48c0-829b-51a8e3666b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directory = r'' ## Enter you Dataset path here\n",
    "SIZE = 64\n",
    "dataset = []  #We are using a list format to handle data. INPUT DATA \n",
    "label = []  #Place holders to define add labels. We will add 0 to all real images and 1 to deepfake. 0 AND 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87092b9-e643-429c-b3ac-db4a5dff839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepfake_images = os.listdir(image_directory + 'df/')\n",
    "for i, image_name in enumerate(deepfake_images):    \n",
    "    \n",
    "    if (image_name.split('.')[1] == 'jpg'):\n",
    "        image = cv2.imread(image_directory + 'df/' + image_name)\n",
    "        image = Image.fromarray(image, 'RGB')\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386a6de2-703c-4a7b-b035-6798787ed26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images = os.listdir(image_directory + 'real/')\n",
    "for i, image_name in enumerate(real_images):    \n",
    "    \n",
    "    if (image_name.split('.')[1] == 'jpg'):\n",
    "        image = cv2.imread(image_directory + 'real/' + image_name)\n",
    "        image = Image.fromarray(image, 'RGB')\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e9d5e0-12f5-418d-b791-579fc4aa40c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.array(dataset)\n",
    "label = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5695bbd8-74c3-45d0-b29b-590f050f51b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, label, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893ffabf-8455-4351-ba0e-893b0e63d544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import normalize\n",
    "X_train = normalize(X_train, axis=1)\n",
    "X_test = normalize(X_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5089ec4a-85a6-4c85-bfb1-8b34f466914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (SIZE, SIZE, 3)  \n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=INPUT_SHAPE))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), kernel_initializer = 'he_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), kernel_initializer = 'he_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), kernel_initializer = 'he_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2864be9-783c-448c-ba3c-3269cab969a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',             \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1f9fff-540d-4168-9ff3-6e48278f16ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, \n",
    "                         y_train, \n",
    "                         batch_size = 32, \n",
    "                         verbose = 1, \n",
    "                         epochs = 1,      \n",
    "                         validation_data=(X_test,y_test),\n",
    "                         shuffle = False\n",
    "                     )\n",
    "model.save(r'model/model.h5')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e034c6-6370-4e84-85a2-3e1b55710c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7379848-e60a-47f4-955c-3b610a81ecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0471ab-6407-4d90-9550-2b655282f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, acc = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy = \", (acc * 100.0), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7bb66c-d927-490f-9499-6d992c959758",
   "metadata": {},
   "outputs": [],
   "source": [
    "mythreshold=0.5\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = (model.predict(X_test)>= mythreshold).astype(int)\n",
    "cm=confusion_matrix(y_test, y_pred)  \n",
    "\n",
    "group_names = ['True Negative','False Positive','False Negative','True Positive']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm.flatten()/np.sum(cm)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm, annot=labels, fmt=\"\", cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b672c4cb-302a-42be-b01d-c5991d6731b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC\n",
    "from sklearn.metrics import roc_curve\n",
    "y_preds = model.predict(X_test).ravel()\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_preds)\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'y--')\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfa1772-9804-4a6f-b4da-4217c9883fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC\n",
    "#Area under the curve (AUC) for ROC plot can be used to understand hpw well a classifier \n",
    "#is performing. \n",
    "#% chance that the model can distinguish between positive and negative classes.\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "auc_value = auc(fpr, tpr)\n",
    "print(\"Area under curve, AUC = \", auc_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8baf8d-33ad-4dcd-a917-c432e9d4d0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
